# -*- coding: utf-8 -*-
"""image_editor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zo_cWhcoX5fq1dg6lHRtuT-GPX8gF7zm
"""

pip install opencv-python numpy

pip install transformers

!nvidia-smi

# prompt: import drive and mount google drive
from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/MyDrive/

!ls /content/drive/MyDrive/lubna.jpeg

import cv2

# Image path with double backslashes
image_path = "lubna.jpeg"

# Alternatively, use a raw string
# image_path = r"C:\Users\lubna\OneDrive\Pictures\Saved Pictures\WhatsApp Image 2022-08-24 at 4.56.51 PM.jpeg"

# Load the image
img = cv2.imread(image_path)

# Continue with the rest of your code (e.g., face detection)

# Import necessary libraries
import cv2
import numpy as np

# Load the pre-trained face detector
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Load an image from file
image_path = img
img = cv2.imread(image_path)

from google.colab.patches import cv2_imshow
import cv2

# Image path with double backslashes
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Alternatively, use a raw string
# image_path = r"C:\Users\lubna\OneDrive\Pictures\Saved Pictures\lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Convert the image to grayscale for face detection
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Perform face detection
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    # Draw rectangles around detected faces
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # Resize the image for display
    resized_img = cv2.resize(img, (400, 400))  # Adjust the size as needed

    # Display the resized image with detected faces using cv2_imshow
    cv2_imshow(resized_img)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Convert the image to grayscale for face detection
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Perform face detection
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    # Apply cartoon effect to the entire image
    cartoon = cv2.stylization(img, sigma_s=150, sigma_r=0.25)

    # Resize the original image and cartoon effect image
    #  resized_img = cv2.resize(img, (400, 400))  # Adjust the size as needed
    resized_cartoon = cv2.resize(cartoon, (400, 400))  # Adjust the size as needed

    # Concatenate the resized original image and cartoon effect image horizontally
    output_image = np.concatenate((resized_img, resized_cartoon), axis=1)

    # Display the resized original image and cartoon effect side by side
    cv2_imshow(output_image)

from google.colab.patches import cv2_imshow
import cv2

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Display the original image
    # print("Original Image:")
    # cv2_imshow(img)

    # Apply multiple filters/effects
    filters = [
        ("Cartoon Effect", cv2.stylization, []),
        ("Grayscale", cv2.cvtColor, [cv2.COLOR_BGR2GRAY]),
        # Add more filters as needed
    ]

    # Set the output size for display
    output_size = (400, 400)  # Adjust the size as needed

    # Apply and display each filter
    for filter_name, filter_function, args in filters:
        # Apply the filter
        if args:
            result = filter_function(img, *args)
        else:
            result = filter_function(img)

        # Resize the result image
        resized_result = cv2.resize(result, output_size)

        # Display the result
        print(f"{filter_name}:")
        cv2_imshow(resized_result)

from google.colab.patches import cv2_imshow
import cv2

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Set the output size for display
    output_size = (400, 400)  # Adjust the size as needed

    # Display the original image
    print("Original Image:")
    resized_img = cv2.resize(img, output_size)
    cv2_imshow(resized_img)

    # Apply multiple filters/effects
    filters = [
        ("Cartoon Effect", cv2.stylization, []),
        ("Grayscale", cv2.cvtColor, [cv2.COLOR_BGR2GRAY]),
        ("Blur", cv2.GaussianBlur, [(5, 5), 0]),
        ("Canny Edge Detection", cv2.Canny, [50, 150]),
        ("Invert Colors", cv2.bitwise_not, []),
        # Add more filters as needed
    ]

    # Apply and display each filter
    for filter_name, filter_function, args in filters:
        # Apply the filter
        if args:
            result = filter_function(img, *args)
        else:
            result = filter_function(img)

        # Resize the result image
        resized_result = cv2.resize(result, output_size)

        # Display the result
        print(f"{filter_name}:")
        cv2_imshow(resized_result)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Custom sepia filter function
def apply_sepia(image):
    kernel = np.array([[0.393, 0.769, 0.189],
                       [0.349, 0.686, 0.168],
                       [0.272, 0.534, 0.131]])
    sepia_image = cv2.transform(image, kernel)
    sepia_image = np.clip(sepia_image, 0, 255).astype(np.uint8)
    return sepia_image

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Display the original image
    # print("Original Image:")
    # cv2_imshow(img)

    # Set the desired output size
    output_size = (300, 300)

    # Apply multiple filters/effects
    filters = [
        ("Cartoon Effect", cv2.stylization, []),
        ("Grayscale", cv2.cvtColor, [cv2.COLOR_BGR2GRAY]),
        ("Blur", cv2.GaussianBlur, [(5, 5), 0]),
        ("Canny Edge Detection", cv2.Canny, [50, 150]),
        ("Invert Colors", cv2.bitwise_not, []),
        ("Sepia", apply_sepia, []),  # Custom sepia function
        ("Rotate 90 degrees Clockwise", cv2.rotate, [cv2.ROTATE_90_CLOCKWISE]),
        ("Rotate 180 degrees", cv2.rotate, [cv2.ROTATE_180]),



      ("Rotate 90 degrees Counter-Clockwise", cv2.rotate, [cv2.ROTATE_90_COUNTERCLOCKWISE]),

        ("Twilight Shifted Colormap", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT_SHIFTED]),
        ("Cool Colormap", cv2.applyColorMap, [cv2.COLORMAP_COOL]),
        ("Ocean Colormap", cv2.applyColorMap, [cv2.COLORMAP_OCEAN]),

        # Additional filters
        ("Jet Colormap", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Autumn Colormap", cv2.applyColorMap, [cv2.COLORMAP_AUTUMN]),
        ("Winter Colormap", cv2.applyColorMap, [cv2.COLORMAP_WINTER]),
        ("Spring Colormap", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("HSV", cv2.cvtColor, [cv2.COLOR_BGR2HSV]),
        ("LAB", cv2.cvtColor, [cv2.COLOR_BGR2Lab]),
        ("Pink Color", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Colormap", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Colormap", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),
        ("Parula Colormap", cv2.applyColorMap, [cv2.COLORMAP_PARULA]),
        ("Bone Colormap", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Jet Colormap", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Hue Variation", cv2.applyColorMap, [cv2.COLORMAP_HSV]),
        ("Pink Variation", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Variation", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Variation", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),
        ("Winter Variation", cv2.applyColorMap, [cv2.COLORMAP_WINTER]),
        ("Spring Variation", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("Parula Variation", cv2.applyColorMap, [cv2.COLORMAP_PARULA]),
        ("Bone Variation", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Jet Variation", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("HSV Variation", cv2.applyColorMap, [cv2.COLORMAP_HSV]),
        ("LAB Variation", cv2.applyColorMap, [cv2.COLORMAP_PLASMA]),
        ("YUV Variation", cv2.applyColorMap, [cv2.COLORMAP_SUMMER]),
        ("Copper Variation", cv2.applyColorMap, [cv2.COLORMAP_COOL]),
        ("Pink Variation", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Variation", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Variation", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),
        ("Viridis Colormap", cv2.applyColorMap, [cv2.COLORMAP_VIRIDIS]),
        ("Plasma Colormap", cv2.applyColorMap, [cv2.COLORMAP_PLASMA]),
        ("Spring Variation", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("Inferno Variation", cv2.applyColorMap, [cv2.COLORMAP_INFERNO]),
        ("Magma Variation", cv2.applyColorMap, [cv2.COLORMAP_MAGMA]),
        ("Jet Variation", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Hot Variation", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Parula Variation", cv2.applyColorMap, [cv2.COLORMAP_PARULA]),
        ("Bone Variation", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Jet Variation", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("HSV Variation", cv2.applyColorMap, [cv2.COLORMAP_HSV]),
        ("LAB Variation", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("YUV Variation", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Copper Variation", cv2.applyColorMap, [cv2.COLORMAP_TURBO]),
        ("Pink Variation", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
         ("Jet Colormap", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Autumn Colormap", cv2.applyColorMap, [cv2.COLORMAP_AUTUMN]),
        ("Winter Colormap", cv2.applyColorMap, [cv2.COLORMAP_WINTER]),
        ("Spring Colormap", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("HSV", cv2.cvtColor, [cv2.COLOR_BGR2HSV]),
        ("LAB", cv2.cvtColor, [cv2.COLOR_BGR2Lab]),
        ("Pink Color", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Colormap", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Colormap", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),

        # Add more filters as needed
    ]

    # Apply and display each filter
    for filter_name, filter_function, args in filters:
        # Apply the filter
        if args:
            result = filter_function(img, *args)
        else:
            result = filter_function(img)

        # Resize the output to the specified size
        result_resized = cv2.resize(result, output_size)

        # Display the result
        print(f"{filter_name}:")
        cv2_imshow(result_resized)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Set the output size for display
    output_size = (400, 400)  # Adjust the size as needed

    # Simple border/frame
    border_color = (0, 255, 0)  # Green color
    border_size = 20
    img_with_border = cv2.copyMakeBorder(img, border_size, border_size, border_size, border_size, cv2.BORDER_CONSTANT, value=border_color)

    # Resize the image with the border
    resized_img_with_border = cv2.resize(img_with_border, output_size)

    # Display the image with the border
    print("Image with Border:")
    cv2_imshow(resized_img_with_border)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Display the original image
    # print("Original Image:")
    # cv2_imshow(img)

    # Set the desired output size
    output_size = (400, 400)

    # Apply simple border/frame
    border_color = (0, 255, 0)  # Green color
    border_size = 20
    img_with_border = cv2.copyMakeBorder(img, border_size, border_size, border_size, border_size, cv2.BORDER_CONSTANT, value=border_color)

    # Resize the image with border
    img_with_border_resized = cv2.resize(img_with_border, output_size)

    # Display the image with the border and resized
    print("Image with Border and Resized:")
    cv2_imshow(img_with_border_resized)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_uniform_borders(image):
    # Get image dimensions
    height, width, _ = image.shape

    # Define border colors and initial thickness
    border_colors = [(0, 0, 255), (0, 255, 0), (255, 255, 0)]  # Blue, Green, Yellow
    border_thickness = 5

    # Draw borders
    for i, color in enumerate(border_colors):
        # Calculate starting point and size for each rectangle
        start_point = (border_thickness * i, border_thickness * i)
        end_point = (width - border_thickness * i, height - border_thickness * i)

        # Draw the rectangle
        cv2.rectangle(image, start_point, end_point, color, border_thickness)

    return image

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Set the output size for display
    output_size = (400, 400)  # Adjust the size as needed

    # Add uniform borders to the image
    img_with_uniform_borders = add_uniform_borders(img.copy())

    # Resize the image with uniform borders
    resized_img_with_uniform_borders = cv2.resize(img_with_uniform_borders, output_size)

    # Display the image with uniform borders
    print("Image with Uniform Borders:")
    cv2_imshow(resized_img_with_uniform_borders)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image):
    # Get image dimensions
    height, width, _ = image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
    ]

    # Draw borders with different styles
    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color
        cv2.rectangle(image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Add dashed lines manually
        if line_style == cv2.LINE_AA:
            line_interval = 20
            for i in range(0, width, line_interval):
                cv2.line(image, (i, 0), (i + line_interval // 2, 0), border_color, thickness=5)

            for i in range(0, height, line_interval):
                cv2.line(image, (0, i), (0, i + line_interval // 2), border_color, thickness=5)

        # Set the output size for display
        output_size = (300, 300)  # Adjust the size as needed

        # Resize the image with the current border style and color
        resized_image = cv2.resize(image, output_size)

        # Display the resized image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(resized_image)

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Add different borders to the image
    add_different_borders(img.copy())

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(400, 400)):
    # Resize the image to the specified output size
    resized_image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = resized_image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Crosshatch", cv2.LINE_AA),
    ]

    # Draw borders with different styles on the resized image
    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color on the resized image
        cv2.rectangle(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Add additional border styles on the resized image
        if style_name == "Thick Solid Line":
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=cv2.LINE_AA)
        elif style_name == "Double Line":
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(resized_image, (10, 10), (width - 10, height - 10), border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Crosshatch":
            cv2.line(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.line(resized_image, (width, 0), (0, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Display the resized image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(resized_image)

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Add different borders to the image with the specified output size
    add_different_borders(img.copy(), output_size=(400, 400))

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(400, 400)):
    # Resize the image to the specified output size
    resized_image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = resized_image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Crosshatch", cv2.LINE_AA),
        ("Double Line with Different Colors", cv2.LINE_AA),
        ("Gradient Border 1", cv2.LINE_AA),
        ("Gradient Border 2", cv2.LINE_AA),
    ]

    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color on the resized image
        cv2.rectangle(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Add additional border styles on the resized image
        if style_name == "Thick Solid Line":
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=cv2.LINE_AA)
        elif style_name == "Double Line":
            margin = 5
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(resized_image, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Crosshatch":
            cv2.line(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.line(resized_image, (width, 0), (0, height), border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Double Line with Different Colors":
            color1 = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()
            color2 = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()
            margin = 5
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), color1, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(resized_image, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          color2, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Gradient Border 1":
            gradient = np.linspace(0, 255, width, dtype=np.uint8)
            gradient_color = cv2.applyColorMap(gradient, cv2.COLORMAP_JET)
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), gradient_color[0][0].tolist(), thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Gradient Border 2":
            gradient = np.linspace(0, 255, width, dtype=np.uint8)
            gradient_color = cv2.applyColorMap(gradient, cv2.COLORMAP_HSV)
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), gradient_color[0][0].tolist(), thickness=5, lineType=cv2.LINE_AA)

        # Display the resized image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(resized_image)

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Add different borders to the image with the specified output size
    add_different_borders(img.copy(), output_size=(400, 400))

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(400, 400)):
    # Resize the image to the specified output size
    image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Double Line with Transparency", cv2.LINE_AA),
    ]

    # Draw borders with different styles
    for style_name, line_style in border_styles:
        # Create a copy of the resized image for each style
        img_with_border = image.copy()

        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color
        cv2.rectangle(img_with_border, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Add additional border styles
        if style_name == "Thick Solid Line":
            cv2.rectangle(img_with_border, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=cv2.LINE_AA)
        elif style_name == "Double Line":
            margin = 5
            cv2.rectangle(img_with_border, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(img_with_border, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(img_with_border, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(img_with_border, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Double Line with Transparency":
            alpha = 0.5  # Set transparency level (0.0 - fully transparent, 1.0 - fully opaque)
            margin = 5
            cv2.rectangle(img_with_border, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(img_with_border, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.addWeighted(img_with_border, alpha, img_with_border, 1 - alpha, 0, img_with_border)

        # Display the image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(img_with_border)

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Add different borders to the image with the specified output size
    add_different_borders(img.copy(), output_size=(400, 400))

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(400, 400)):
    # Resize the image to the specified output size
    resized_image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = resized_image.shape

    # Create a transparent overlay
    overlay = np.zeros_like(resized_image, dtype=np.uint8)

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Double Line with Transparency", cv2.LINE_AA),
    ]

    # Draw borders with different styles on the overlay
    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Add additional border styles
        if style_name == "Thick Solid Line":
            cv2.rectangle(overlay, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=cv2.LINE_AA)
        elif style_name == "Double Line":
            margin = 5
            cv2.rectangle(overlay, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(overlay, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(overlay, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(overlay, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Double Line with Transparency":
            alpha = 0.5  # Set transparency level (0.0 - fully transparent, 1.0 - fully opaque)
            margin = 5
            cv2.rectangle(overlay, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(overlay, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)

    # Blend the resized image and the overlay with transparency
    result = cv2.addWeighted(resized_image, 1, overlay, 1, 0)

    # Display the image with the different border styles
    print("Image with Different Borders:")
    cv2_imshow(result)

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Add different borders to the image with the specified output size
    add_different_borders(img.copy(), output_size=(400, 400))

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Function to apply beauty filters on the image
def apply_beauty_filters(image):
    # Set the desired output size
    output_size = (200, 200)

    # Apply beauty filters
    beauty_filters = [
        ("Smooth Skin", smooth_skin, [image, 9, 75, 75]),
        ("Remove Double Chin", remove_double_chin, [image]),
        ("Spot Healing", spot_healing, [image]),
        ("Enhance Cheeks", enhance_cheeks, [image]),
        ("Brighten Eyes", brighten_eyes, [image]),
        ("Remove Dark Circles", remove_dark_circles, [image]),
        ("Whiten Teeth", whiten_teeth, [image]),
        # Add more beauty filters as needed
    ]

    # Apply and display each beauty filter
    for filter_name, filter_function, args in beauty_filters:
        # Apply the beauty filter
        result = filter_function(*args)

        # Resize the output to the specified size
        result_resized = cv2.resize(result, output_size)

        # Display the result
        print(f"{filter_name} Result:")
        cv2_imshow(result_resized)

# Function to smooth the skin using bilateral filter
def smooth_skin(image, d, sigmaColor, sigmaSpace):
    return cv2.bilateralFilter(image, d, sigmaColor, sigmaSpace)

# Function to remove double chin (example: resizing)
def remove_double_chin(image):
    return cv2.resize(image, (image.shape[1], int(image.shape[0] * 0.9)))

# Function for spot healing (example: inpainting)
# def spot_healing(image):
#     mask = cv2.imread("spot_healing_mask.png", cv2.IMREAD_GRAYSCALE)  # You need to create a mask for inpainting
#     return cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)
def spot_healing(image, spot_size=11):
    return cv2.GaussianBlur(image, (spot_size, spot_size), 0)
# Function to enhance cheeks (example: color adjustment)
def enhance_cheeks(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv[:, :, 1] = hsv[:, :, 1] * 1.2  # Increase saturation for enhancing cheeks
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

# Function to brighten eyes (example: histogram equalization)
def brighten_eyes(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l = cv2.equalizeHist(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

# Function to remove dark circles (example: blending with surrounding pixels)
def remove_dark_circles(image):
    mask = cv2.imread("dark_circles_mask.png", cv2.IMREAD_GRAYSCALE)  # You need to create a mask for blending
    return cv2.seamlessClone(image, image, mask, (image.shape[1] // 2, image.shape[0] // 2), cv2.NORMAL_CLONE)

# Function to whiten teeth (example: color adjustment)
def whiten_teeth(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l = cv2.equalizeHist(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the image
img = cv2.imread(image_path)

# Check if the image is loaded successfully
if img is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Display the original image
    # print("Original Image:")
    # cv2_imshow(img)

    # Apply beauty filters on the original image
    apply_beauty_filters(img)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Function to convert image depth if needed
def convert_image_depth(image):
    # Check if the image has 64-bit float depth
    if image.dtype == np.float64:
        # Convert to 8-bit unsigned integer
        image = cv2.convertScaleAbs(image)
    return image

# Function to apply brightness adjustment
def apply_brightness(image, factor):
    return cv2.convertScaleAbs(image, alpha=factor, beta=0)

# Function to apply contrast adjustment
def apply_contrast(image, factor):
    return cv2.convertScaleAbs(image, alpha=factor, beta=0)

# Function to apply saturation adjustment
def apply_saturation(image, factor):
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * factor, 0, 255)
    return cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)

# Function to apply exposure adjustment
def apply_exposure(image, factor):
    return cv2.convertScaleAbs(image, alpha=factor, beta=0)

# Function to resize an image
def resize_image(image, output_size):
    return cv2.resize(image, output_size)

# Image path
image_path = r"/content/drive/MyDrive/lubna.jpeg"

# Load the original image
original_image = cv2.imread(image_path)

# Check if the image is loaded successfully
if original_image is None:
    print(f"Error: Unable to load the image from {image_path}")
else:
    # Display the original image
    # print("Original Image:")
    # cv2_imshow(original_image)

    # Output size for displayed images
    output_size = (200, 200)

    # Apply and display adjustments one by one
    adjustments = [
        ("Brightness", apply_brightness, 1.2),
        ("Contrast", apply_contrast, 1.5),
        ("Saturation", apply_saturation, 1.2),
        ("Exposure", apply_exposure, 1.2),
        # ... Add more adjustments ...
    ]

    for adjustment_name, adjustment_function, adjustment_factor in adjustments:
        # Apply the adjustment
        adjusted_image = adjustment_function(original_image, adjustment_factor)

        # Resize the adjusted image
        adjusted_image_resized = resize_image(adjusted_image, output_size)

        # Display the resized adjusted image
        print(f"{adjustment_name} Adjustment:")
        cv2_imshow(adjusted_image_resized)

import subprocess

# Install required packages
subprocess.run(["pip", "install", "opencv-python"])
subprocess.run(["pip", "install", "tensorflow"])
subprocess.run(["pip", "install", "imageai"])

!pip install opencv-python
!pip install tensorflow
!pip install imageai

!pip install tensorflow
!pip install matplotlib

!wget http://images.cocodataset.org/zips/train2014.zip
!unzip train2014.zip

!pip install pycocotools



!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip
!unzip annotations_trainval2014.zip

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout
import matplotlib.pyplot as plt
import json
import os

annotations_path = "annotations/captions_train2014.json"

with open(annotations_path, "r") as f:
    annotations = json.load(f)

# Extract image paths and captions
image_paths = []
captions = []

for annotation in annotations["annotations"]:
    image_paths.append("/content/drive/MyDrive/train2014/" + str(annotation["image_id"]) + ".jpg")
    captions.append(annotation["caption"])

print("Number of images:", len(image_paths))
print("Number of captions:", len(captions))



max_vocab_size = 5000

tokenizer = Tokenizer(num_words=max_vocab_size, oov_token="<OOV>")
tokenizer.fit_on_texts(captions)

total_words = len(tokenizer.word_index) + 1
print("Total words in the vocabulary:", total_words)

# Create input sequences and target sequences
input_sequences = tokenizer.texts_to_sequences(captions)
max_sequence_length = max(len(seq) for seq in input_sequences)

input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding="post")

print("Max sequence length:", max_sequence_length)
print("Example input sequence:", input_sequences[0])

embedding_dim = 256
lstm_units = 512

input_image = Input(shape=(max_sequence_length,))
input_caption = Input(shape=(max_sequence_length,))

embedding_layer = Embedding(input_dim=total_words, output_dim=embedding_dim, input_length=max_sequence_length)
embedded_caption = embedding_layer(input_caption)

lstm_layer = LSTM(units=lstm_units, return_sequences=True)
lstm_output = lstm_layer(embedded_caption)

merged = tf.keras.layers.Concatenate(axis=-1)([tf.expand_dims(input_image, axis=-1), lstm_output])
lstm_output = LSTM(units=lstm_units)(merged)

output = Dense(total_words, activation="softmax")(lstm_output)

model = Model(inputs=[input_image, input_caption], outputs=output)
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

model.summary()



from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
from io import BytesIO

# Load the processor and model
model_name = 'Salesforce/blip-image-captioning-base'
processor = BlipProcessor.from_pretrained(model_name)
model = BlipForConditionalGeneration.from_pretrained(model_name)

# Replace 'your_image_bytes' with the actual variable containing the image bytes
# For example, if you have the image stored in a file, you can read the bytes from the file
with open("/content/drive/MyDrive/lubna.jpeg", "rb") as f:
    your_image_bytes = f.read()

# Process the image with the processor
inputs = processor(images=Image.open(BytesIO(your_image_bytes)), return_tensors="pt")

# Generate captions using the model
outputs = model.generate(**inputs)
captions = processor.decode(outputs[0], skip_special_tokens=True)

print("Generated caption:", captions)

# from transformers import BlipProcessor, BlipForConditionalGeneration
# from PIL import Image
# from io import BytesIO

# # Load the processor and model
# model_name = 'Salesforce/blip-image-captioning-base'
# processor = BlipProcessor.from_pretrained(model_name)
# model = BlipForConditionalGeneration.from_pretrained(model_name)

# # Replace 'your_image_bytes' with the actual variable containing the image bytes
# # For example, if you have the image stored in a file, you can read the bytes from the file
# with open("/content/drive/MyDrive/lubna.jpeg", "rb") as f:
#     your_image_bytes = f.read()

# # Process the image with the processor
# inputs = processor(images=Image.open(BytesIO(your_image_bytes)), return_tensors="pt")

# # Generate multiple captions using the model
# num_captions = 10  # Set the number of captions you want
# captions = []

# for _ in range(num_captions):
#     outputs = model.generate(**inputs)
#     caption = processor.decode(outputs[0], skip_special_tokens=True)
#     captions.append(caption)

# print("Generated captions:")
# for i, caption in enumerate(captions, start=1):
#     print(f"{i}. {caption}")

pip install torch transformers

import torch

# from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer
# from PIL import Image
# from io import BytesIO

# # Load the Blip processor and model
# blip_model_name = 'Salesforce/blip-image-captioning-base'
# blip_processor = BlipProcessor.from_pretrained(blip_model_name)
# blip_model = BlipForConditionalGeneration.from_pretrained(blip_model_name)

# # Load the GPT-2 model and tokenizer for language model testing
# gpt_model_name = "gpt2"
# gpt_tokenizer = GPT2Tokenizer.from_pretrained(gpt_model_name)
# gpt_model = GPT2LMHeadModel.from_pretrained(gpt_model_name)

# # Replace 'your_image_bytes' with the actual variable containing the image bytes
# # For example, if you have the image stored in a file, you can read the bytes from the file
# with open("/content/drive/MyDrive/lubna.jpeg", "rb") as f:
#     your_image_bytes = f.read()

# # Process the image with the Blip processor
# inputs_blip = blip_processor(images=Image.open(BytesIO(your_image_bytes)), return_tensors="pt")

# # Generate multiple captions using the Blip model
# outputs_blip = blip_model.generate(**inputs_blip, max_length=50, num_beams=5, num_return_sequences=3)
# captions_list = [blip_processor.decode(output, skip_special_tokens=True) for output in outputs_blip]

# # Print the list of generated captions
# print("Generated captions:")
# for i, caption in enumerate(captions_list):
#     print(f"{i + 1}. {caption}")

# # Test the captions with the GPT-2 language model
# for caption in captions_list:
#     input_ids = gpt_tokenizer.encode(caption, return_tensors="pt")
#     outputs_gpt = gpt_model(input_ids)
#     generated_text = gpt_tokenizer.decode(outputs_gpt.logits[:, -1, :].argmax(dim=-1))
#     # print(f"Generated text from GPT-2: {generated_text}")

# from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer
# from PIL import Image
# from io import BytesIO

# # Load the Blip processor and model
# blip_model_name = 'Salesforce/blip-image-captioning-base'
# blip_processor = BlipProcessor.from_pretrained(blip_model_name)
# blip_model = BlipForConditionalGeneration.from_pretrained(blip_model_name)

# # Load the GPT-2 model and tokenizer for language model testing
# gpt_model_name = "gpt2"
# gpt_tokenizer = GPT2Tokenizer.from_pretrained(gpt_model_name)
# gpt_model = GPT2LMHeadModel.from_pretrained(gpt_model_name)

# # Replace 'your_image_bytes' with the actual variable containing the image bytes
# # For example, if you have the image stored in a file, you can read the bytes from the file
# with open("/content/drive/MyDrive/lubna.jpeg", "rb") as f:
#     your_image_bytes = f.read()

# # Process the image with the Blip processor
# inputs_blip = blip_processor(images=Image.open(BytesIO(your_image_bytes)), return_tensors="pt")

# # Generate multiple captions using the Blip model
# num_return_sequences = 15  # You can adjust this number as needed
# num_beams = max(num_return_sequences, 5)  # Set num_beams to be equal to or greater than num_return_sequences
# outputs_blip = blip_model.generate(**inputs_blip, max_length=50, num_beams=num_beams, num_return_sequences=num_return_sequences)
# captions_list = [blip_processor.decode(output, skip_special_tokens=True) for output in outputs_blip]

# # Print the list of generated captions
# print("Generated captions:")
# for i, caption in enumerate(captions_list):
#     print(f"{i + 1}. {caption}")

# # Test the captions with the GPT-2 language model
# for caption in captions_list:
#     input_ids = gpt_tokenizer.encode(caption, return_tensors="pt")
#     outputs_gpt = gpt_model(input_ids)
#     generated_text = gpt_tokenizer.decode(outputs_gpt.logits[:, -1, :].argmax(dim=-1))
#     # print(f"Generated text from GPT-2: {generated_text}")

!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose
!pip install huggingface_hub
!pip install llama-cpp-python==0.1.78
!pip install numpy==1.23.4

model_name_or_path = "TheBloke/Llama-2-13B-chat-GGML"
model_basename = "llama-2-13b-chat.ggmlv3.q5_1.bin"

from huggingface_hub import hf_hub_download

from llama_cpp import Llama

model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)

# GPU
lcpp_llm = None
lcpp_llm = Llama(
    model_path=model_path,
    n_threads=2, # CPU cores
    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.
    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.
    )

lcpp_llm.params.n_gpu_layers

# prompt = "Write a insertion sort in python"
prompt = "An awesome girl with long hair and blue eyes."
prompt_template=f'''SYSTEM: Your are super camption creator using description of image provided by user. You write 5 creative and trending captions.

USER: {prompt}

ASSISTANT:
'''

response=lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,
                  repeat_penalty=1.2, top_k=150,
                  echo=True)

print(response)

print(response["choices"][0]["text"])




# prompt_template = '''hii baby...

# USER: {}'''

# # Insert the generated caption into the prompt
# prompt = prompt_template.format( captions)

# # Now you can use the modified prompt for further processing
# print("Modified prompt:", prompt)

