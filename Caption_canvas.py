# -*- coding: utf-8 -*-
"""PixelPoet_Pro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yagNzVL2ffZbrN4GNizHsrZt4EElfqcR

#  Installing Essential Libraries

**To enable image and numerical processing capabilities, we'll install two powerful Python libraries:**

- **OpenCV (cv2):** A versatile library for image and video processing, offering features like:
    - Image manipulation: Resizing, cropping, and enhancing images.
    - Object detection: Identifying specific objects within images.
- **NumPy:** A fundamental library for numerical computing, providing:
    - Efficient array operations: Essential for handling image data and model outputs.
    - Data manipulation: Preprocessing and reshaping data for AI models.
"""

pip install opencv-python numpy

"""#  Preparing for Face Detection"""

# Import necessary libraries
import cv2
import numpy as np

# Load the pre-trained face detector
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Load an image from file
# image_path = img
# img = cv2.imread(image_path)

"""#  Interactive Face Detection in Colab

This code enables users to upload an image and employs OpenCV to detect and highlight faces within it.

"""

from google.colab import files
from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Upload image from local machine
uploaded = files.upload()

# Check if any file is uploaded
if len(uploaded.keys()) == 0:
    print("Error: No file uploaded.")
else:
    # Assuming only one file is uploaded, you can modify it accordingly
    image_path = list(uploaded.keys())[0]

    # Load the uploaded image
    img = cv2.imdecode(np.frombuffer(uploaded[image_path], np.uint8), -1)

    # Check if the image is loaded successfully
    if img is None:
        print(f"Error: Unable to load the image from {image_path}")
    else:
        # Convert the image to grayscale for face detection
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Define a Haar Cascade for face detection
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        # Perform face detection
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

        # Draw rectangles around detected faces
        for (x, y, w, h) in faces:
            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)

        # Resize the image for display
        resized_img = cv2.resize(img, (400, 400))  # Adjust the size as needed

        # Display the resized image with detected faces using cv2_imshow
        cv2_imshow(resized_img)

"""# Applied Filters on Given Image"""

# Assuming 'img' contains the image loaded in Cell 1

# Check if the image is loaded successfully
if img is None:
    print("Error: Image not loaded. Please run Cell 1 to upload an image.")
else:
    # Display the original image
    # print("Original Image:")
    # cv2_imshow(img)

    # Set the desired output size
    output_size = (300, 300)

    # Apply multiple filters/effects
    filters = [
        ("Cartoon Effect", cv2.stylization, []),
        ("Grayscale", cv2.cvtColor, [cv2.COLOR_BGR2GRAY]),
        ("Blur", cv2.GaussianBlur, [(5, 5), 0]),
        ("Canny Edge Detection", cv2.Canny, [50, 150]),
        ("Invert Colors", cv2.bitwise_not, []),

        ("Rotate 90 degrees Clockwise", cv2.rotate, [cv2.ROTATE_90_CLOCKWISE]),
        ("Rotate 180 degrees", cv2.rotate, [cv2.ROTATE_180]),



      ("Rotate 90 degrees Counter-Clockwise", cv2.rotate, [cv2.ROTATE_90_COUNTERCLOCKWISE]),

        ("Twilight Shifted Colormap", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT_SHIFTED]),
        ("Cool Colormap", cv2.applyColorMap, [cv2.COLORMAP_COOL]),
        ("Ocean Colormap", cv2.applyColorMap, [cv2.COLORMAP_OCEAN]),

        # Additional filters
        ("Jet Colormap", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Autumn Colormap", cv2.applyColorMap, [cv2.COLORMAP_AUTUMN]),
        ("Winter Colormap", cv2.applyColorMap, [cv2.COLORMAP_WINTER]),
        ("Spring Colormap", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("HSV", cv2.cvtColor, [cv2.COLOR_BGR2HSV]),
        ("LAB", cv2.cvtColor, [cv2.COLOR_BGR2Lab]),
        ("Pink Color", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Colormap", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Colormap", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),
        ("Parula Colormap", cv2.applyColorMap, [cv2.COLORMAP_PARULA]),
        ("Bone Colormap", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Jet Colormap", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Hue Variation", cv2.applyColorMap, [cv2.COLORMAP_HSV]),
        ("Pink Variation", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Variation", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Variation", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),
        ("Winter Variation", cv2.applyColorMap, [cv2.COLORMAP_WINTER]),
        ("Spring Variation", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("Parula Variation", cv2.applyColorMap, [cv2.COLORMAP_PARULA]),
        ("Bone Variation", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Jet Variation", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("HSV Variation", cv2.applyColorMap, [cv2.COLORMAP_HSV]),
        ("LAB Variation", cv2.applyColorMap, [cv2.COLORMAP_PLASMA]),
        ("YUV Variation", cv2.applyColorMap, [cv2.COLORMAP_SUMMER]),
        ("Copper Variation", cv2.applyColorMap, [cv2.COLORMAP_COOL]),
        ("Pink Variation", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Variation", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Variation", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),
        ("Viridis Colormap", cv2.applyColorMap, [cv2.COLORMAP_VIRIDIS]),
        ("Plasma Colormap", cv2.applyColorMap, [cv2.COLORMAP_PLASMA]),
        ("Spring Variation", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("Inferno Variation", cv2.applyColorMap, [cv2.COLORMAP_INFERNO]),
        ("Magma Variation", cv2.applyColorMap, [cv2.COLORMAP_MAGMA]),
        ("Jet Variation", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Hot Variation", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Parula Variation", cv2.applyColorMap, [cv2.COLORMAP_PARULA]),
        ("Bone Variation", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Jet Variation", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("HSV Variation", cv2.applyColorMap, [cv2.COLORMAP_HSV]),
        ("LAB Variation", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("YUV Variation", cv2.applyColorMap, [cv2.COLORMAP_BONE]),
        ("Copper Variation", cv2.applyColorMap, [cv2.COLORMAP_TURBO]),
        ("Pink Variation", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
         ("Jet Colormap", cv2.applyColorMap, [cv2.COLORMAP_JET]),
        ("Autumn Colormap", cv2.applyColorMap, [cv2.COLORMAP_AUTUMN]),
        ("Winter Colormap", cv2.applyColorMap, [cv2.COLORMAP_WINTER]),
        ("Spring Colormap", cv2.applyColorMap, [cv2.COLORMAP_SPRING]),
        ("HSV", cv2.cvtColor, [cv2.COLOR_BGR2HSV]),
        ("LAB", cv2.cvtColor, [cv2.COLOR_BGR2Lab]),
        ("Pink Color", cv2.applyColorMap, [cv2.COLORMAP_PINK]),
        ("Hot Colormap", cv2.applyColorMap, [cv2.COLORMAP_HOT]),
        ("Twilight Colormap", cv2.applyColorMap, [cv2.COLORMAP_TWILIGHT]),
    ]

    # Apply and display each filter
    for filter_name, filter_function, args in filters:
        # Apply the filter
        if args:
            result = filter_function(img, *args)
        else:
            result = filter_function(img)

        # Resize the output to the specified size
        result_resized = cv2.resize(result, output_size)

        # Display the result
        print(f"{filter_name}:")
        cv2_imshow(result_resized)

"""#  Adding a Simple Border to the Image"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Assuming 'img' contains the dynamically uploaded image from Cell 1

# Check if the image is loaded successfully
if img is None:
    print("Error: Image not loaded. Please run Cell 1 to upload an image.")
else:
    # Set the output size for display
    output_size = (400, 400)  # Adjust the size as needed

    # Simple border/frame
    border_color = (0, 255, 0)  # Green color
    border_size = 20
    img_with_border = cv2.copyMakeBorder(img, border_size, border_size, border_size, border_size, cv2.BORDER_CONSTANT, value=border_color)

    # Resize the image with the border
    resized_img_with_border = cv2.resize(img_with_border, output_size)

    # Display the image with the border
    print("Image with Border:")
    cv2_imshow(resized_img_with_border)

"""# Creating Uniform Borders Around the Image"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_uniform_borders(image):
    # Get image dimensions
    height, width, _ = image.shape

    # Define border colors and initial thickness
    border_colors = [(0, 0, 255), (0, 255, 0), (255, 255, 0)]  # Blue, Green, Yellow
    border_thickness = 5

    # Draw borders
    for i, color in enumerate(border_colors):
        # Calculate starting point and size for each rectangle
        start_point = (border_thickness * i, border_thickness * i)
        end_point = (width - border_thickness * i, height - border_thickness * i)

        # Draw the rectangle
        cv2.rectangle(image, start_point, end_point, color, border_thickness)

    return image

# Assuming 'img' contains the dynamically uploaded image from Cell 1

# Check if the image is loaded successfully
if img is None:
    print("Error: Image not loaded. Please run Cell 1 to upload an image.")
else:
    # Set the output size for display
    output_size = (300, 300)  # Adjust the size as needed

    # Add uniform borders to the image
    img_with_uniform_borders = add_uniform_borders(img.copy())

    # Resize the image with uniform borders
    resized_img_with_uniform_borders = cv2.resize(img_with_uniform_borders, output_size)

    # Display the image with uniform borders
    print("Image with Uniform Borders:")
    cv2_imshow(resized_img_with_uniform_borders)

"""# Applying Borders with Different Styles and Colors"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image):
    # Get image dimensions
    height, width, _ = image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
    ]

    # Draw borders with different styles
    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color
        cv2.rectangle(image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Add dashed lines manually
        if line_style == cv2.LINE_AA:
            line_interval = 20
            for i in range(0, width, line_interval):
                cv2.line(image, (i, 0), (i + line_interval // 2, 0), border_color, thickness=5)

            for i in range(0, height, line_interval):
                cv2.line(image, (0, i), (0, i + line_interval // 2), border_color, thickness=5)

        # Set the output size for display
        output_size = (300, 300)  # Adjust the size as needed

        # Resize the image with the current border style and color
        resized_image = cv2.resize(image, output_size)

        # Display the resized image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(resized_image)

# Assuming 'img' contains the dynamically uploaded image from Cell 1

# Check if the image is loaded successfully
if img is None:
    print("Error: Image not loaded. Please run Cell 1 to upload an image.")
else:
    # Add different borders to the image
    add_different_borders(img.copy())

"""# Exploring More Border Styles with Resizable Output"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(300, 300)):
    # Resize the image to the specified output size
    resized_image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = resized_image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Crosshatch", cv2.LINE_AA),
    ]

    # Draw borders with different styles on the resized image
    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color on the resized image
        cv2.rectangle(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Add additional border styles on the resized image
        if style_name == "Thick Solid Line":
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=cv2.LINE_AA)
        elif style_name == "Double Line":
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(resized_image, (10, 10), (width - 10, height - 10), border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Crosshatch":
            cv2.line(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.line(resized_image, (width, 0), (0, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Display the resized image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(resized_image)

# Assuming 'img' contains the image loaded in Cell 1

# Check if the image is loaded successfully
if img is None:
    print("Error: Image not loaded. Please run Cell 1 to upload an image.")
else:
    # Add different borders to the image with the specified output size
    add_different_borders(img.copy(), output_size=(400, 400))

"""# Expanding Border Styles with Double Lines, Gradients, and Resizing
Key Enhancements:

Double Lines with Different Colors: Two rectangles with distinct random colors.
Gradient Borders: Rectangles using gradients (JET and HSV colormaps).
Flexible Output Size: output_size parameter for resizing images before border application.
"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(300, 300)):
    # Resize the image to the specified output size
    resized_image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = resized_image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Crosshatch", cv2.LINE_AA),
        ("Double Line with Different Colors", cv2.LINE_AA),
        ("Gradient Border 1", cv2.LINE_AA),
        ("Gradient Border 2", cv2.LINE_AA),
    ]

    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color on the resized image
        cv2.rectangle(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=line_style)

        # Add additional border styles on the resized image
        if style_name == "Thick Solid Line":
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=line_style)
        elif style_name == "Double Line":
            margin = 5
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=line_style)
            cv2.rectangle(resized_image, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=line_style)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=line_style)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(resized_image, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=line_style)
        elif style_name == "Crosshatch":
            cv2.line(resized_image, (0, 0), (width, height), border_color, thickness=5, lineType=line_style)
            cv2.line(resized_image, (width, 0), (0, height), border_color, thickness=5, lineType=line_style)
        elif style_name == "Double Line with Different Colors":
            color1 = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()
            color2 = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()
            margin = 5
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), color1, thickness=5, lineType=line_style)
            cv2.rectangle(resized_image, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          color2, thickness=5, lineType=line_style)
        elif style_name == "Gradient Border 1":
            gradient = np.linspace(0, 255, width, dtype=np.uint8)
            gradient_color = cv2.applyColorMap(gradient, cv2.COLORMAP_JET)
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), gradient_color[0][0].tolist(), thickness=5, lineType=line_style)
        elif style_name == "Gradient Border 2":
            gradient = np.linspace(0, 255, width, dtype=np.uint8)
            gradient_color = cv2.applyColorMap(gradient, cv2.COLORMAP_HSV)
            cv2.rectangle(resized_image, (5, 5), (width - 5, height - 5), gradient_color[0][0].tolist(), thickness=5, lineType=line_style)

        # Display the resized image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(resized_image)

# Assuming 'img' is the image uploaded in Cell 1
# If not, please replace 'img' with the correct variable
add_different_borders(img.copy(), output_size=(300, 300))

"""# Incorporating Transparency for Double Lines and Error Handling
Key Enhancements:

Transparent Double Line: Achieved using cv2.addWeighted to blend the image with itself, creating a translucent effect.
Error Handling: Checks if the image is loaded before proceeding.
Output Size Flexibility: Function accepts an output_size parameter for resizing.
"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(300, 300)):
    # Resize the image to the specified output size
    image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = image.shape

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Double Line with Transparency", cv2.LINE_AA),
    ]

    # Draw borders with different styles
    for style_name, line_style in border_styles:
        # Create a copy of the resized image for each style
        img_with_border = image.copy()

        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Draw the rectangle with the specified style and random color
        cv2.rectangle(img_with_border, (0, 0), (width, height), border_color, thickness=5, lineType=cv2.LINE_AA)

        # Add additional border styles
        if style_name == "Thick Solid Line":
            cv2.rectangle(img_with_border, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=cv2.LINE_AA)
        elif style_name == "Double Line":
            margin = 5
            cv2.rectangle(img_with_border, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(img_with_border, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(img_with_border, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(img_with_border, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Double Line with Transparency":
            alpha = 0.5  # Set transparency level (0.0 - fully transparent, 1.0 - fully opaque)
            margin = 5
            cv2.rectangle(img_with_border, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(img_with_border, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.addWeighted(img_with_border, alpha, img_with_border, 1 - alpha, 0, img_with_border)

        # Display the image with the current border style and color
        print(f"Image with {style_name} Border (Random Color):")
        cv2_imshow(img_with_border)

# Assuming 'img' contains the dynamically uploaded image from Cell 1
# Set the desired output size
output_size = (300, 300)

# Add different borders to the dynamically uploaded image
add_different_borders(img.copy(), output_size)

"""#  Key Features:

Multiple Border Styles: Supports solid, thick, double, dashed, dotted, and transparent double lines.
Random Border Colors: Generates random colors for most styles, creating visually appealing variations.
Flexible Output Size: Allows resizing images before applying borders using the output_size parameter.
Error Handling: Checks if the image is loaded before processing, preventing errors.
Transparent Double Line: Achieves a translucent effect for the double line border using cv2.addWeighted.
Process Breakdown:

Function Call:
Calls add_different_borders with the image and desired output size.
Error Handling:
Verifies that the image is loaded; prints an error message if not.
Image Resizing:
Resizes the image to the specified output_size.
Overlay Creation:
Creates a transparent overlay with the same dimensions as the resized image.
Border Drawing:
Iterates through the border_styles list.
Generates a random color for each border (except transparent double line).
Draws each border style on the overlay using appropriate OpenCV functions (cv2.rectangle, cv2.polylines).
Transparency Blending:
For the transparent double line, blends the overlay with itself using cv2.addWeighted, creating the translucent effect.
Image Combination:
Combines the resized image and the overlay with borders using cv2.addWeighted.
Displaying Results:
Shows the final image with the applied borders.
"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

def add_different_borders(image, output_size=(300, 300)):
    # Resize the image to the specified output size
    resized_image = cv2.resize(image, output_size)

    # Get resized image dimensions
    height, width, _ = resized_image.shape

    # Create a transparent overlay
    overlay = np.zeros_like(resized_image, dtype=np.uint8)

    # Define border styles
    border_styles = [
        ("Solid Line", cv2.LINE_AA),
        ("Thick Solid Line", cv2.LINE_AA),
        ("Double Line", cv2.LINE_AA),
        ("Dashed Line", cv2.LINE_AA),
        ("Dotted Line", cv2.LINE_AA),
        ("Double Line with Transparency", cv2.LINE_AA),
    ]

    # Draw borders with different styles on the overlay
    for style_name, line_style in border_styles:
        # Generate a random color for each border
        border_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8).tolist()

        # Add additional border styles
        if style_name == "Thick Solid Line":
            cv2.rectangle(overlay, (5, 5), (width - 5, height - 5), border_color, thickness=15, lineType=cv2.LINE_AA)
        elif style_name == "Double Line":
            margin = 5
            cv2.rectangle(overlay, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(overlay, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dashed Line":
            line_interval = 20
            dashed_line = np.array([[i, 0] for i in range(0, width, line_interval)], dtype=np.int32)
            cv2.polylines(overlay, [dashed_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Dotted Line":
            line_interval = 20
            dotted_line = np.array([[0, i] for i in range(0, height, line_interval)], dtype=np.int32)
            cv2.polylines(overlay, [dotted_line], isClosed=False, color=border_color, thickness=5, lineType=cv2.LINE_AA)
        elif style_name == "Double Line with Transparency":
            alpha = 0.5  # Set transparency level (0.0 - fully transparent, 1.0 - fully opaque)
            margin = 5
            cv2.rectangle(overlay, (5, 5), (width - 5, height - 5), border_color, thickness=5, lineType=cv2.LINE_AA)
            cv2.rectangle(overlay, (10 + margin, 10 + margin), (width - 10 - margin, height - 10 - margin),
                          border_color, thickness=5, lineType=cv2.LINE_AA)

    # Blend the resized image and the overlay with transparency
    result = cv2.addWeighted(resized_image, 1, overlay, 1, 0)

    # Display the image with different border styles
    print("Image with Different Borders:")
    cv2_imshow(result)

# Assuming 'img' contains the dynamically uploaded image from Cell 1

# Check if the image is loaded successfully
if img is None:
    print("Error: Image not loaded. Please run Cell 1 to upload an image.")
else:
    # Add different borders to the image with the specified output size
    add_different_borders(img.copy(), output_size=(300, 300))

"""#  Key Features:

- **Multiple Beauty Filters:** Includes functions for skin smoothing, double chin removal, spot healing, cheek enhancement, eye brightening, dark circle removal, and teeth whitening.
- **Flexible Application:** Allows applying filters selectively or in sequence.
- **Customizable Parameters:** Provides parameters for fine-tuning filter effects within functions.
- **Image Resizing:** Resizes outputs to a consistent size for better comparison.
- **Organization and Readability:** Uses descriptive filter names and clear code structure.

**Process Breakdown:**

1. **`apply_beauty_filters` Function:**
   - Takes an image as input.
   - Defines a list of beauty filters, their corresponding functions, and arguments.
   - Iterates through the list, applying each filter and displaying results.
   - Resizes outputs to a specified size.

2. **Individual Filter Functions:**
   - **`smooth_skin`:** Uses bilateral filtering to preserve edges while smoothing.
   - **`remove_double_chin`:** Simplifies double chin removal by resizing the image vertically.
   - **`spot_healing`:** Approximates spot healing using Gaussian blur.
   - **`enhance_cheeks`:** Increases saturation in HSV color space to enhance cheeks.
   - **`brighten_eyes`:** Equalizes the lightness channel in LAB color space to brighten eyes.
   - **`remove_dark_circles`:** Uses seamless cloning with a mask to blend dark circles with surrounding pixels.
   - **`whiten_teeth`:** Equalizes the lightness channel in LAB color space to whiten teeth.

3. **Calling the Function:**
   - Calls `apply_beauty_filters` with the loaded image to apply filters and display results.

"""

from google.colab.patches import cv2_imshow
import cv2

# Function to apply beauty filters on the image
def apply_beauty_filters(image):
    # Set the desired output size
    output_size = (200, 200)

    # Apply beauty filters
    beauty_filters = [
        ("Smooth Skin", smooth_skin, [image, 9, 75, 75]),
        ("Remove Double Chin", remove_double_chin, [image]),
        ("Spot Healing", spot_healing, [image]),
        ("Enhance Cheeks", enhance_cheeks, [image]),
        ("Brighten Eyes", brighten_eyes, [image]),
        ("Remove Dark Circles", remove_dark_circles, [image]),
        ("Whiten Teeth", whiten_teeth, [image]),
        # Add more beauty filters as needed
    ]

    # Apply and display each beauty filter
    for filter_name, filter_function, args in beauty_filters:
        # Apply the beauty filter
        result = filter_function(*args)

        # Resize the output to the specified size
        result_resized = cv2.resize(result, output_size)

        # Display the result
        print(f"{filter_name} :")
        cv2_imshow(result_resized)

# Function to smooth the skin using bilateral filter
def smooth_skin(image, d, sigmaColor, sigmaSpace):
    return cv2.bilateralFilter(image, d, sigmaColor, sigmaSpace)

# Function to remove double chin (example: resizing)
def remove_double_chin(image):
    return cv2.resize(image, (image.shape[1], int(image.shape[0] * 0.9)))

# Function for spot healing (example: inpainting)
def spot_healing(image, spot_size=11):
    return cv2.GaussianBlur(image, (spot_size, spot_size), 0)

# Function to enhance cheeks (example: color adjustment)
def enhance_cheeks(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv[:, :, 1] = hsv[:, :, 1] * 1.2  # Increase saturation for enhancing cheeks
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

# Function to brighten eyes (example: histogram equalization)
def brighten_eyes(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l = cv2.equalizeHist(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

# Function to remove dark circles (example: blending with surrounding pixels)
def remove_dark_circles(image):
    # Assuming you have a mask for blending, otherwise, provide a mask path
    mask_path = "dark_circles_mask.png"
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    return cv2.seamlessClone(image, image, mask, (image.shape[1] // 2, image.shape[0] // 2), cv2.NORMAL_CLONE)

# Function to whiten teeth (example: color adjustment)
def whiten_teeth(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l = cv2.equalizeHist(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

# Apply beauty filters on the dynamically uploaded image from Cell 1 (img)
apply_beauty_filters(img)

"""# Key Features:

Image Depth Handling: Checks for 64-bit float depth and converts to 8-bit unsigned integer if needed, ensuring compatibility with display functions.
Multiple Image Adjustments: Provides functions for adjusting brightness, contrast, saturation, and exposure.
Flexible Application: Allows applying adjustments selectively or in sequence.
Customizable Parameters: Offers adjustment factors for fine-tuning the effects.
Image Resizing: Resizes outputs to a consistent size for better comparison.
Error Handling: Checks for image loading errors.
Organization and Readability: Uses descriptive function names and clear code structure.
Process Breakdown:

Image Loading and Depth Check:
Loads the image (assumed to be in img).
Calls convert_image_depth to convert to 8-bit if necessary.
Adjustment Application and Display:
Iterates through a list of adjustments, each containing:
Adjustment name
Corresponding function
Adjustment factor
Calls the adjustment function with the image and factor.
Resizes the adjusted image to a specified size.
Displays the resized image with its adjustment name.
Key Functions:

convert_image_depth: Converts image depth to 8-bit if needed.
apply_brightness: Adjusts brightness using cv2.convertScaleAbs.
apply_contrast: Adjusts contrast using cv2.convertScaleAbs.
apply_saturation: Adjusts saturation in HSV color space.
apply_exposure: Adjusts exposure using cv2.convertScaleAbs.
resize_image: Resizes an image using cv2.resize.

"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np

# Function to convert image depth if needed
def convert_image_depth(image):
    # Check if the image has 64-bit float depth
    if image.dtype == np.float64:
        # Convert to 8-bit unsigned integer
        image = cv2.convertScaleAbs(image)
    return image

# Function to apply brightness adjustment
def apply_brightness(image, factor):
    return cv2.convertScaleAbs(image, alpha=factor, beta=0)

# Function to apply contrast adjustment
def apply_contrast(image, factor):
    return cv2.convertScaleAbs(image, alpha=factor, beta=0)

# Function to apply saturation adjustment
def apply_saturation(image, factor):
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * factor, 0, 255)
    return cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)

# Function to apply exposure adjustment
def apply_exposure(image, factor):
    return cv2.convertScaleAbs(image, alpha=factor, beta=0)

# Function to resize an image
def resize_image(image, output_size):
    return cv2.resize(image, output_size)

# Assuming 'img' contains the dynamically uploaded image from Cell 1

# Check if the image is loaded successfully
if img is None:
    print("Error: Image not loaded. Please run Cell 1 to upload an image.")
else:
    # Display the original image
    # print("Original Image:")
    # cv2_imshow(img)

    # Output size for displayed images
    output_size = (200, 200)

    # Apply and display adjustments one by one
    adjustments = [
        ("Brightness", apply_brightness, 1.2),
        ("Contrast", apply_contrast, 1.5),
        ("Saturation", apply_saturation, 1.2),
        ("Exposure", apply_exposure, 1.2),
        # ... Add more adjustments ...
    ]

    for adjustment_name, adjustment_function, adjustment_factor in adjustments:
        # Apply the adjustment
        adjusted_image = adjustment_function(img, adjustment_factor)

        # Resize the adjusted image
        adjusted_image_resized = resize_image(adjusted_image, output_size)

        # Display the resized adjusted image
        print(f"{adjustment_name} Adjustment:")
        cv2_imshow(adjusted_image_resized)

"""# **Installing Required Packages:**

This cell installs the following Python packages essential for image processing and machine learning tasks:

- **opencv-python:** Provides tools for image processing and computer vision.
- **tensorflow:** A powerful open-source library for machine learning and deep learning.
- **imageai:** A framework built on top of TensorFlow for simplifying image and video analysis tasks.
"""

import subprocess

# Install required packages
subprocess.run(["pip", "install", "opencv-python"])
subprocess.run(["pip", "install", "tensorflow"])
subprocess.run(["pip", "install", "imageai"])

""" # Installing Required Packages:

This cell directly installs the following Python packages using `!pip install`:

- **opencv-python:** For image processing and computer vision tasks.
- **tensorflow:** A powerful library for machine learning and deep learning.
- **imageai:** A framework built on top of TensorFlow for simplifying image and video analysis.

"""

!pip install opencv-python
!pip install tensorflow
!pip install imageai

"""# Installing TensorFlow and Matplotlib:
TensorFlow: A powerful open-source library for machine learning and deep learning.
Matplotlib: A comprehensive library for creating static, animated, and interactive visualizations.
"""

!pip install tensorflow
!pip install matplotlib

!wget http://images.cocodataset.org/zips/train2014.zip
!unzip train2014.zip

!pip install pycocotools

!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip
!unzip annotations_trainval2014.zip

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout
import matplotlib.pyplot as plt
import json
import os

annotations_path = "annotations/captions_train2014.json"

with open(annotations_path, "r") as f:
    annotations = json.load(f)

# Extract image paths and captions
image_paths = []
captions = []

for annotation in annotations["annotations"]:
    image_paths.append("/content/drive/MyDrive/train2014/" + str(annotation["image_id"]) + ".jpg")
    captions.append(annotation["caption"])

print("Number of images:", len(image_paths))
print("Number of captions:", len(captions))

max_vocab_size = 5000

tokenizer = Tokenizer(num_words=max_vocab_size, oov_token="<OOV>")
tokenizer.fit_on_texts(captions)

total_words = len(tokenizer.word_index) + 1
print("Total words in the vocabulary:", total_words)

# Create input sequences and target sequences
input_sequences = tokenizer.texts_to_sequences(captions)
max_sequence_length = max(len(seq) for seq in input_sequences)

input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding="post")

print("Max sequence length:", max_sequence_length)
print("Example input sequence:", input_sequences[0])

embedding_dim = 256
lstm_units = 512

input_image = Input(shape=(max_sequence_length,))
input_caption = Input(shape=(max_sequence_length,))

embedding_layer = Embedding(input_dim=total_words, output_dim=embedding_dim, input_length=max_sequence_length)
embedded_caption = embedding_layer(input_caption)

lstm_layer = LSTM(units=lstm_units, return_sequences=True)
lstm_output = lstm_layer(embedded_caption)

merged = tf.keras.layers.Concatenate(axis=-1)([tf.expand_dims(input_image, axis=-1), lstm_output])
lstm_output = LSTM(units=lstm_units)(merged)

output = Dense(total_words, activation="softmax")(lstm_output)

model = Model(inputs=[input_image, input_caption], outputs=output)
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

model.summary()

from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
from io import BytesIO

# Assuming 'img' contains the image loaded in Cell 1

# Convert the image to bytes
image_bytes = cv2.imencode('.jpg', img)[1].tobytes()

# Load the processor and model
model_name = 'Salesforce/blip-image-captioning-base'
processor = BlipProcessor.from_pretrained(model_name)
model = BlipForConditionalGeneration.from_pretrained(model_name)

# Process the image with the processor
inputs = processor(images=Image.open(BytesIO(image_bytes)), return_tensors="pt")

# Generate captions using the model
outputs = model.generate(**inputs)
captions = processor.decode(outputs[0], skip_special_tokens=True)

print("Generated caption:", captions)

pip install torch transformers

import torch

!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose
!pip install huggingface_hub
!pip install llama-cpp-python==0.1.78
!pip install numpy==1.23.4

model_name_or_path = "TheBloke/Llama-2-13B-chat-GGML"
model_basename = "llama-2-13b-chat.ggmlv3.q5_1.bin"

from huggingface_hub import hf_hub_download

from llama_cpp import Llama

model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)

# GPU
lcpp_llm = None
lcpp_llm = Llama(
    model_path=model_path,
    n_threads=2, # CPU cores
    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.
    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.
    )

lcpp_llm.params.n_gpu_layers

# prompt = "Write a insertion sort in python"
# prompt = "An awesome girl with long hair and blue eyes."
prompt = captions
prompt_template=f'''SYSTEM: Your are super camption creator using description of image provided by user. You write 10 creative and trending captions.

USER: {prompt}

ASSISTANT:
'''
response=lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,
                  repeat_penalty=1.2, top_k=150,
                  echo=True)
response=lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,
                  repeat_penalty=1.2, top_k=150,
                  echo=True)
print(response["choices"][0]["text"])